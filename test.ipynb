{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import h5py\n",
    "import time\n",
    "import imgaug as ia\n",
    "import imgaug.augmenters as iaa\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "gpus = tf.config.experimental.list_physical_devices(device_type='GPU')\n",
    "cpus = tf.config.experimental.list_physical_devices(device_type='CPU')\n",
    "\n",
    "# tf.config.experimental.set_visible_devices(devices=cpus[0], device_type='CPU')\n",
    "# tf.config.experimental.set_visible_devices(devices=gpus[0], device_type='GPU')\n",
    "# for gpu in gpus:\n",
    "#     tf.config.experimental.set_memory_growth(device=gpu, enable=True)\n",
    "    \n",
    "tf.config.experimental.set_virtual_device_configuration(\n",
    "    gpus[0],\n",
    "    [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=8192)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.models import CNN, MLP\n",
    "from layers.utils import get_custom_objects\n",
    "from layers import densenet, stn, inception_v3, anonymous_net, xception, vgg, resnet, resnet_v2, resnext, mobilenet, mobilenet_v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES = 257\n",
    "IMAGE_SIZE = 224\n",
    "DATA_DIR = 'data/256_ObjectCategories/'\n",
    "CACHE_FILE = 'data/dataset_{}.h5'.format(IMAGE_SIZE)\n",
    "SEED = 1127\n",
    "MODEL_FILE = 'data/model.keras'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class H5Cacher():\n",
    "    \"\"\" H5 数据缓存器 \"\"\"\n",
    "\n",
    "    def __init__(self, path):\n",
    "        self.path = path\n",
    "\n",
    "    def load(self):\n",
    "        data = {}\n",
    "        try:\n",
    "            h5f = h5py.File(self.path, 'r')\n",
    "            for key in h5f.keys():\n",
    "                data[key] = h5f[key][:]\n",
    "        finally:\n",
    "            h5f.close()\n",
    "        return data\n",
    "\n",
    "    def dump(self, data):\n",
    "        try:\n",
    "            h5f = h5py.File(self.path, 'w')\n",
    "            for key in data.keys():\n",
    "                h5f[key] = data[key]\n",
    "        finally:\n",
    "            h5f.close()\n",
    "\n",
    "    def __call__(self, get_data):\n",
    "        def get_data_wrapper():\n",
    "            if os.path.isfile(self.path):\n",
    "                print('data << {}'.format(self.path))\n",
    "                data = self.load()\n",
    "            else:\n",
    "                data = get_data()\n",
    "                print('data >> {}'.format(self.path))\n",
    "                self.dump(data)\n",
    "            return data\n",
    "        return get_data_wrapper\n",
    "\n",
    "@H5Cacher(CACHE_FILE)\n",
    "def read_images():\n",
    "    dir_names = os.listdir(DATA_DIR)\n",
    "    X = []\n",
    "    Y = []\n",
    "    for i, dir_name in enumerate(dir_names):\n",
    "        class_dir = os.path.join(DATA_DIR, dir_name)\n",
    "        if not os.path.isdir(class_dir):\n",
    "            continue\n",
    "        label, name = dir_name.split('.')\n",
    "        label = int(label) - 1\n",
    "        print(\"{}/{} {} \".format(i, len(dir_names), dir_name), end='\\r')\n",
    "        for img_name in os.listdir(class_dir):\n",
    "            img_path = os.path.join(class_dir, img_name)\n",
    "            if not os.path.isfile(img_path):\n",
    "                continue\n",
    "            if not img_path.endswith('.jpg'):\n",
    "                continue\n",
    "            img = read_and_resize(img_path, shape=(IMAGE_SIZE, IMAGE_SIZE))\n",
    "            X.append(img)\n",
    "            Y.append(label)\n",
    "    \n",
    "    data_set = {\n",
    "        'X': np.array(X),\n",
    "        'Y': np.array(Y)\n",
    "    }\n",
    "                \n",
    "    return data_set\n",
    "\n",
    "def get_name_list():\n",
    "    label_to_name = [None for i in range(NUM_CLASSES)]\n",
    "    dir_names = os.listdir(DATA_DIR)\n",
    "    for dir_name in dir_names:\n",
    "        if not os.path.isdir(os.path.join(DATA_DIR, dir_name)):\n",
    "            continue\n",
    "        label, name = dir_name.split('.')\n",
    "        label_to_name[int(label)-1] = name\n",
    "    assert all(label_to_name)\n",
    "    return label_to_name\n",
    "\n",
    "def read_and_resize(img_path, shape=(224, 224)):\n",
    "    img = cv2.cvtColor(cv2.imread(img_path), cv2.COLOR_BGR2RGB)\n",
    "    return cv2.resize(img, shape)\n",
    "\n",
    "def batch_loader(X, y, batch_size=64):\n",
    "\n",
    "    data_size = X.shape[0]\n",
    "    permutation = np.random.permutation(data_size)\n",
    "    batch_permutation_indices = [permutation[i: i + batch_size] for i in range(0, data_size, batch_size)]\n",
    "    for batch_permutation in batch_permutation_indices:\n",
    "        yield X[batch_permutation], y[batch_permutation]\n",
    "        \n",
    "def change_range(X):\n",
    "    \"\"\" 将 [0, 255] 变为 [-1, 1]\"\"\"\n",
    "    X = np.divide(X, 127.5, dtype=np.float32) - 1\n",
    "#     X -= np.mean(X, axis=0)\n",
    "#     X /= np.std(X, axis=0)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sometimes = lambda aug: iaa.Sometimes(0.5, aug)\n",
    "\n",
    "seq = iaa.Sequential(\n",
    "    [\n",
    "        # apply the following augmenters to most images\n",
    "        iaa.Fliplr(0.5), # horizontally flip 50% of all images\n",
    "        # crop images by -5% to 10% of their height/width\n",
    "        sometimes(iaa.CropAndPad(\n",
    "            percent=(-0.05, 0.1),\n",
    "            pad_mode=ia.ALL,\n",
    "            pad_cval=(0, 255)\n",
    "        )),\n",
    "        sometimes(iaa.Affine(\n",
    "            scale={\"x\": (0.9, 1.1), \"y\": (0.9, 1.1)}, # scale images to 80-120% of their size, individually per axis\n",
    "            translate_percent={\"x\": (-0.1, 0.1), \"y\": (-0.1, 0.1)}, # translate by -20 to +20 percent (per axis)\n",
    "            rotate=(-10, 10), # rotate by -45 to +45 degrees\n",
    "            shear=(-3, 3), # shear by -16 to +16 degrees\n",
    "            order=[0, 1], # use nearest neighbour or bilinear interpolation (fast)\n",
    "            cval=(0, 255), # if mode is constant, use a cval between 0 and 255\n",
    "            mode=ia.ALL # use any of scikit-image's warping modes (see 2nd image from the top for examples)\n",
    "        )),\n",
    "        iaa.OneOf([\n",
    "            iaa.GaussianBlur((0, 3.0)), # blur images with a sigma between 0 and 3.0\n",
    "            iaa.AverageBlur(k=(2, 7)), # blur image using local means with kernel sizes between 2 and 7\n",
    "            iaa.MedianBlur(k=(3, 7)), # blur image using local medians with kernel sizes between 2 and 7\n",
    "        ]),\n",
    "        iaa.OneOf([\n",
    "            iaa.Dropout((0.01, 0.1), per_channel=0.5), # randomly remove up to 10% of the pixels\n",
    "            iaa.CoarseDropout((0.03, 0.15), size_percent=(0.02, 0.05), per_channel=0.2),\n",
    "        ]),\n",
    "        sometimes(iaa.AdditiveGaussianNoise(loc=0, scale=(0.0, 0.05*255), per_channel=0.5)),\n",
    "        iaa.Resize({\"height\":IMAGE_SIZE, \"width\":IMAGE_SIZE})\n",
    "    ],\n",
    "    random_order=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epoch = 1000\n",
    "batch_size = 16\n",
    "learning_rate = 1e-4\n",
    "num_epoch_for_lr_decay = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "base_model = tf.keras.applications.MobileNetV2(input_shape=(IMAGE_SIZE, IMAGE_SIZE, 3), weights=None, include_top=False)\n",
    "# base_model.trainable = False\n",
    "inputs = tf.keras.Input(shape=(IMAGE_SIZE, IMAGE_SIZE, 3))\n",
    "x = inputs\n",
    "x = base_model(x)\n",
    "# x = tf.keras.layers.Flatten()(x)\n",
    "# x = tf.keras.layers.Dense(NUM_CLASSES)(x)\n",
    "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "x = tf.keras.layers.Dense(NUM_CLASSES)(x)\n",
    "outputs = tf.keras.layers.Softmax()(x)\n",
    "model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# blocks = [6, 12, 24, 16]\n",
    "# theta = np.array([[1., 0, 0], [0, 1., 0]], dtype=np.float32)\n",
    "# theta = theta.flatten()\n",
    "\n",
    "inputs = tf.keras.Input(shape=(IMAGE_SIZE, IMAGE_SIZE, 3))\n",
    "x = inputs\n",
    "x = mobilenet_v2.MobileNetV2()(x)\n",
    "# x = tf.keras.layers.Flatten()(x)\n",
    "# x = tf.keras.layers.Dense(NUM_CLASSES)(x)\n",
    "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "x = tf.keras.layers.Dense(NUM_CLASSES)(x)\n",
    "outputs = tf.keras.layers.Softmax()(x)\n",
    "model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(MODEL_FILE)\n",
    "model = tf.keras.models.load_model(MODEL_FILE, custom_objects=get_custom_objects())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set = read_images()\n",
    "X, y = data_set['X'], data_set['Y']\n",
    "# X = change_range(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.05, random_state=SEED)\n",
    "train_size, test_size = len(X_train), len(X_test)\n",
    "name_list = get_name_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step_per_epoch = train_size // batch_size\n",
    "\n",
    "lr_schedule = tf.keras.optimizers.schedules.InverseTimeDecay(\n",
    "    learning_rate,\n",
    "    decay_steps=step_per_epoch*num_epoch_for_lr_decay,\n",
    "    decay_rate=1,\n",
    "    staircase=False)\n",
    "optimizer = tf.keras.optimizers.Adam(lr_schedule)\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "\n",
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')\n",
    "\n",
    "test_loss = tf.keras.metrics.Mean(name='test_loss')\n",
    "test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='test_accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_on_batch(X_batch, y_batch):\n",
    "    with tf.GradientTape() as tape:\n",
    "        y_pred = model(X_batch, training=True)\n",
    "        loss = loss_object(y_true=y_batch, y_pred=y_pred)\n",
    "        loss = tf.reduce_mean(loss)\n",
    "    grads = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(grads_and_vars=zip(grads, model.trainable_variables))\n",
    "    \n",
    "    train_loss(loss)\n",
    "    train_accuracy(y_batch, y_pred)\n",
    "    return loss\n",
    "\n",
    "@tf.function\n",
    "def test_on_batch(X_batch, y_batch):\n",
    "    y_pred = model(X_batch, training=False)\n",
    "    t_loss = loss_object(y_batch, y_pred)\n",
    "    \n",
    "    test_loss(t_loss)\n",
    "    test_accuracy(y_batch, y_pred)\n",
    "    return t_loss\n",
    "\n",
    "for epoch in range(num_epoch):\n",
    "    \n",
    "    train_loss.reset_states()\n",
    "    train_accuracy.reset_states()\n",
    "    test_loss.reset_states()\n",
    "    test_accuracy.reset_states()\n",
    "    \n",
    "    for batch_index, (X_batch, y_batch) in enumerate(batch_loader(X_train, y_train, batch_size=batch_size)):\n",
    "        X_batch = np.array(seq(images=X_batch))\n",
    "        X_batch = change_range(X_batch)\n",
    "        loss = train_on_batch(X_batch, y_batch)\n",
    "        template = '[Training] Epoch {}, Batch {}/{}, Loss: {}, Accuracy: {:.2%} '\n",
    "        print(template.format(epoch+1,\n",
    "                              batch_index,\n",
    "                              train_size // batch_size,\n",
    "                              loss,\n",
    "                              train_accuracy.result()),\n",
    "             end='\\r')\n",
    "\n",
    "    for batch_index, (X_batch, y_batch) in enumerate(batch_loader(X_test, y_test, batch_size=batch_size)):\n",
    "        X_batch = change_range(X_batch)\n",
    "        loss = test_on_batch(X_batch, y_batch)\n",
    "        template = '[Testing] Epoch {}, Batch {}/{}, Loss: {}, Accuracy: {:.2%} '\n",
    "        print(template.format(epoch+1,\n",
    "                              batch_index,\n",
    "                              test_size // batch_size,\n",
    "                              loss,\n",
    "                              test_accuracy.result()),\n",
    "             end='\\r')\n",
    "        \n",
    "    template = 'Epoch {}, Loss: {}, Accuracy: {:.2%}, Test Loss: {}, Test Accuracy: {:.2%} '\n",
    "    print(template.format(epoch+1,\n",
    "                         train_loss.result(),\n",
    "                         train_accuracy.result(),\n",
    "                         test_loss.result(),\n",
    "                         test_accuracy.result()))\n",
    "    \n",
    "    model.save(MODEL_FILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_accuracy.reset_states()\n",
    "for batch_index, (X_batch, y_batch) in enumerate(batch_loader(X_test, y_test, batch_size=batch_size)):\n",
    "    X_batch_ori = X_batch # \n",
    "    X_batch = change_range(X_batch)\n",
    "    y_pred = model(X_batch)\n",
    "    test_accuracy(y_batch, y_pred)\n",
    "    y_pred_label = np.array([np.argmax(one_hot) for one_hot in y_pred.numpy()])\n",
    "    template = '[Testing] Batch {}/{}, Accuracy: {:.2%} '\n",
    "    print(template.format(batch_index,\n",
    "                          test_size // batch_size,\n",
    "                          test_accuracy.result()),\n",
    "             end='\\r')\n",
    "#     for i in range(X_batch.shape[0]):\n",
    "#         plt.imshow(X_batch_ori[i])\n",
    "#         plt.title('Real: {}, Predict: {}'.format(name_list[y_batch[i]], name_list[y_pred_label[i]]))\n",
    "#         plt.show()\n",
    "        \n",
    "template = 'Test Accuracy: {:.2%} '\n",
    "print(template.format(test_accuracy.result()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "img_path = 'data/TestSet/163.playing-card/Test_163_0009.jpg'\n",
    "img_path = 'data/TestSet/096.hammock/Test_096_0002.jpg'\n",
    "img = cv2.cvtColor(cv2.imread(img_path), cv2.COLOR_BGR2RGB)\n",
    "# img = img[0:200,0:200]\n",
    "img = cv2.resize(img, (224, 224))\n",
    "X_batch_ori = np.array([img])\n",
    "X_batch = change_range(X_batch_ori)\n",
    "y_pred = model(X_batch)\n",
    "y_pred_label = np.array([np.argmax(one_hot) for one_hot in y_pred.numpy()])\n",
    "plt.imshow(img)\n",
    "plt.title(' Predict: {}'.format(name_list[y_pred_label[0]]))\n",
    "plt.show()\n",
    "\n",
    "X_batch_trans = transform_layer(X_batch)\n",
    "plt.imshow((X_batch_trans[0] + 1)/2)\n",
    "plt.show()\n",
    "print(transform_layer.get_dense_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('tf2': conda)",
   "language": "python",
   "name": "python37664bittf2condad2284dedc2eb448ea8250faba7f9d846"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}